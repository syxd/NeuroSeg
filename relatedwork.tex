\section{Related Work}
\label{sec:related work}

\subsection{Techniques for Robust Neuron Reconstruction}
\label{sec:neuron reconstruction}
Early conventional techniques for neuron reconstruction typically employ traditional image processing algorithms, such as snakes~\cite{Wang2011, Cai2006}, principal curves~\cite{Bas2011}, graph theory~\cite{Peng2010a, Yang2013, De2016}, model-fitting~\cite{Zhao2011, Santamaria2015}, watershed~\cite{Navlakha2013, Suembuel2016}, energy minimization~\cite{Quan2013, Liu2016}, mean-shift clustering~\cite{Frasconi2014}, ray-shooting~\cite{Wu2014, Liu2019}, fast-marching~\cite{Peng2011, Xiao2013, Liu2018} and so on.
Unfortunately, all these conventional algorithms rely on hand-crafted features and carefully tuned parameters, and usually tend to fail when the image quality is poor.
%TReMAP~\cite{Zhou2016}, NGPST~\cite{Quan2015},

To improve the reconstruction performance from low-quality image blocks, some machine learning based methods were introduced to extract neuron voxels for neuron reconstruction. This kind of methods employs various classifiers with hand-crafted features, such as support vector machine (SVM)~\cite{Chen2015}, minimum spanning tree~\cite{Basu2016}, Bayesian probabilistic model~\cite{Radojevic2017}, Bootstrap aggregating~\cite{Wang2017}, gradient boosting decision trees (GBDT)~\cite{Gu2017}, Markov chain Monte Carlo (MCMC)~\cite{Skibbe2015, Skibbe2019} and so on.
However, the main limitation of these methods is that hand-crafted features usually suffer from limited representation capability for accurate recognition, considering more challenging and complex image blocks.


Recently, we have evidenced an increasing development of deep learning based methods~\cite{Li2017, Zhou2018, Xu2016}, which bring the power of DNNs to improve the reconstruction performance. Instead of manually designing sophisticated features, these methods learn feature representations in a data-driven way and extract more distinctive features. When more complicated classifiers are employed to segment neuron voxels from image blocks, these methods can achieve more robust reconstruction results. 
Though great improvement of neuron reconstruction could be achieved, these deep learning based methods rely on strong supervision for network training, i.e., manual annotations for neuron voxels.
Unfortunately, due to the complicated morphology of neurons and the low quality of OM images, such annotations are very costly to obtain in terms of both time and labor.
%Though great improvement of neuron reconstruction could be achieved on a specific dataset, these deep learning based methods rely on strong supervision for network training, i.e., manual annotations for dense voxels. Unfortunately, due to the dense distribution of neuronal populations in the OM images, such annotations are extremely time-consuming and require expensive labor to obtain.
%
In comparison, we propose a novel iterative framework to progressively improve the 3D DNN-based neuron reconstruction performance without using manual annotations.


\subsection{Large-scale Neuron Reconstruction}
\label{sec:largescale}

Most existing neuron reconstruction methods focus on robust and accuracy neuron reconstruction from local noisy image blocks. Despite substantial advancements in these methods, they often need to load all image voxels into memory before the reconstruction and the sheer volume of a large-scale image is far beyond the processing capability for them, especially on the memory cost and tracing time.
%
In recent years, some attempts have been made to reconstruct neurons from large-scale OM images, such as Neuron Crawler~\cite{Zhou2015}, UltraTracer~\cite{Peng2017} and MEIT~\cite{Wang2018}.
To tackle the challenges caused by the large volume of images, a common solution is to reconstruct neuronal morphology block by block. Each block is cropped from the raw image and is much smaller in size than the raw image.
Therefore, existing tracing methods, such as APP2~\cite{Xiao2013}, MOST~\cite{Wu2014} and FMST~\cite{Yang2018}, can be directly used as the base tracer in their methods to trace neurites in each block. Then the reconstructed neurites in all blocks are assembled to obtain the final reconstruction.


However, all of these methods focus on single neuron reconstruction and the images they process usually contain only one single neuron.
%Despite their great improvement in neuron reconstruction from large-scale images, all of them mainly focus on single neuron reconstruction and the images they process usually contain only one neuron.
%However, a large-scale OM brain image usually contains dense neuronal populations in practice.
Since these methods are mainly designed for large-scale single neuron reconstruction, they are not useful for dense neuronal populations, in which neurons frequently contact or close to each other in the image.
%These methods can be extended to sparsely spaced neurons but are not useful for dense neuronal populations, in which neurites frequently contact or close to each other in the image. 
%If closely spaced neurites belonging to different neurons are not distinguished, individual neurons may be assembled in the reconstruction. 
When the closely spaced neurites that belong to different neurons are not be distinguished, neurons can not be separately reconstructed.
Therefore, a complete reconstruction of dense neuronal populations from large-scale images still remains challenging for existing methods.
%
In this work, we introduce a new algorithm to reconstruct neuronal populations from large-scale or even ultra-large-scale images.
