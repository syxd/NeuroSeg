\section{Experiments and Results}
\label{sec:experiments}

We evaluate our neuronal population reconstruction approach on an ultra-scale OM image of a mouse brain slice in dimension of $25397\times 18516\times 869$ ($761$ GB), as Fig.~\ref{fig:brain} shows.
%
This image was captured by the VISoR imaging system~\cite{Wang2019} at a physical resolution of $0.5$ \SI{}{\micro\metre} $\times0.5$ \SI{}{\micro\metre} $\times 0.5$ \SI{}{\micro\metre} per voxel. 
%
The image intensity is in 16-bit dynamic range, which preserves sufficient signal details.
In order to evaluate our PLNPR method for neuronal reconstruction from local blocks, we first conduct extensive experiments on the VISoR-40 dataset which we build for evaluation and the BigNeuron dataset~\cite{peng2015}. 
%
Then we test our UltraNPR algorithm for neuronal population reconstruction from the ultra-scale OM brain image.

\subsection{Evaluation of PLNPR on VISoR-40 Dataset}
\label{sec:exp_PLNPR_VISoR}

\subsubsection{VISoR-40 Dataset}
Though many neuron tracing techniques have been proposed, no dataset of OM images has been built for dense neuronal population reconstruction.
We construct a neuron image dataset ``VISoR-40'' (available at \url{https://braindata.bitahub.com/Neuronal_population_reconstruction.html}) for evaluation. 
The VISoR-40 dataset consists of 40 OM image blocks cropped from the mouse brain image. The dimension of the blocks ranges from $419 \times1197 \times 224$ to $869 \times1853 \times 575$.
%
We randomly select $32$ blocks for progressively training the segmentation network without manual annotations in our PLNPR.
%
%The remaining 8 blocks were manually labeled for validation and test.  
For the remaining 8 blocks, one is used for validation and the other seven blocks are used for testing.
Each of them was first independently labeled by two experts. Then, by cross-checking their results, the agreed annotations were approved by another expert to generate the final ground truth.
%One of the eight annotated blocks is used for validation for network training, and the other seven blocks are used for test. 


\subsubsection{Experimental Settings and Evaluation Metrics}


Pytorch is adopted to implement the DSN model. At each iteration of the progressive learning, the network is trained from scratch with weights initialized from a Gaussian distribution with zero-mean and variance of $ 0.01 $. The optimization is realized with the stochastic gradient descent algorithm with the Adam update rule (batch size of 1, weight decay of $ 0.0005 $, and momentum of $ 0.9 $). The base learning rate is set to $ 0.001 $ and descended with the ``poly" learning rate policy (power of $ 0.9 $ and the maximum iteration number of $ 24000 $). 
%The cube size is set as $160\times 160\times 160$ considering the GPU memory limitation.

To quantitatively evaluate our method, four commonly used metrics defined in NGPST~\cite{Quan2015}, including precision, recall, F-Score, and Jaccard, are computed to measure the fidelity between the reconstruction results and the ground truth. 
Their definitions are defined as follows:
\begin{flalign}
&Precision(R,G)= \frac{\vert R \cap G\vert}{\vert R\vert} = \frac{\vert TP\vert}{\vert R\vert}, & \\
&Recall(R,G) = \frac{\vert R\cap G\vert}{\vert G\vert} = \frac{\vert TP\vert}{\vert G\vert}, & \\
&F{-}Score(R,G) = 2 \cdot{\frac{Precision \times Recall}{Precision + Recall}},&\\
%&F{-}Score(R,G)= \frac{2\vert R \cap G\vert}{\vert R\vert + \vert G\vert} = \frac{2\vert TP\vert}{\vert R\vert + \vert G\vert}, & \\
&Jaccard(R,G)= \frac{\vert R\cap G\vert}{\vert R\cup G\vert} = \frac{\vert TP\vert}{\vert R\cup G\vert}, &
\label{equ: metrics}
\end{flalign}
%
where $R$ denotes the set of points on the reconstructed neurons, $G$ denotes the set of neuron points in the ground truth and $TP$ denotes the set of true positive points, $|\cdot|$ denotes the number of points in a set.
%We follow the rule of determining true positive points described in~\cite{Quan2015}. 
The four metrics are first computed on each individual neuron and then averaged in a neuronal population by weighting each neuron with the total length of its neurites, same as \cite{Quan2015}.



\subsubsection{Progressive Learning}

The key idea of PLNPR is to progressively improve the performance of neuron reconstruction by making the neuron segmentation network and the conventional tracing method complementary and synergistic without using any manual annotations.
In order to demonstrate the performance improvement, four widely-used tracing methods, including APP1~\cite{Peng2011}, APP2~\cite{Xiao2013}, MOST~\cite{Wu2014}, and NGPST~\cite{Quan2015}, are tested as the base tracer in our PLNPR framework. 
We use their implementations in the software Vaa3D~\cite{Peng2014}. 
%
Eight iterations are tested on our VISoR-40 dataset.
The improvement of neuronal population reconstruction is shown in Fig.~\ref{fig:ablation_study_plnpr}~(a).
We only show the F-Score which is widely used to reflect the overall performance of neuron reconstruction.
%
Moreover, the reconstructed neurons on a test block at different iterations are shown in Fig.~\ref{fig:trace_iterations}.
%
More qualitative and quantitative results are reported in the supplementary materials.
The results show that our progressive learning strategy effectively facilitates conventional tracing methods to reconstruct more complete neurons.
In addition, the performance improvement gets stable after five iterations for all the tested tracing methods. 

\begin{figure*}[t]
	\centering
	\subfloat[]{
		\begin{minipage}[b]{0.33\linewidth}
			\centering
			\includegraphics[height=3.8cm]{./Illustrations/PLNPR_fscore.pdf}
		\end{minipage}}
	\subfloat[]{
		\begin{minipage}[b]{0.33\linewidth}
			\centering
			\includegraphics[height=3.8cm]{./Illustrations/PLNPR_networks.pdf}
		\end{minipage}}
	\subfloat[]{
		\begin{minipage}[b]{0.33\linewidth}
			\centering
			\includegraphics[height=3.8cm]{./Illustrations/PLNPR_alpha.pdf}
		\end{minipage}}
	\caption{ Comparison of different parameters in our PLNPR framework on the VISoR-40 dataset.
		(a) Comparisons of F-scores of the neuronal population reconstruction at different iterations with four base tracers respectively. 
		(b) F-Scores of neuron reconstruction at five iterations using three deep segmentation networks. 
		Combining any base tracer and any one of the three neuron segmentation DNNs, our PLNPR scheme progressively improves the reconstruction performance.
		(c) Neuron reconstruction performance with different $\alpha$ in Eq.~\eqref{equ: enhance} for image enhancement.} %From left to right, the value of $\alpha$ increases from $0$ to $1$ by a step of $0.1$.
	
	\label{fig:ablation_study_plnpr}
\end{figure*}


\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{./Illustrations/trace_iterations3.pdf}
	\caption{Neuronal population reconstruction results of a test block at different iterations in our PLNPR framework using four neuron tracing methods.} 
	% APP1~\cite{Peng2011}, APP2~\cite{Xiao2013}, MOST\cite{Wu2014} and NGPST~\cite{Quan2015}.}
	\label{fig:trace_iterations}
\end{figure}

\delete{
\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\columnwidth]{./Illustrations/trace_networks_fscore11.pdf}
	\caption{F-Score of neuron reconstruction on the VISoR-40 testing dataset at five iterations. Combining any one of the three neuron segmentation networks, our approach progressively improves the reconstruction performance.}
	\label{fig:fscore_DNNs}
\end{figure}
}


\subsubsection{Neuron Segmentation Network}

To further verify the effectiveness and robustness of our progressive learning strategy, we test three commonly-used deep segmentation networks, including 3D DSN~\cite{Dou2017}, 3D U-Net~\cite{Cicek2016}, and a 3D version of HRNet~\cite{Sun2019}, for generating the neuron probability map.
Five iterations are tested on our VISoR-40 dataset, and the F-Score improvement of reconstruction results is shown in Fig.~\ref{fig:ablation_study_plnpr}~(b). 
%
It can be seen that our PLNPR algorithm effectively improves the neuron reconstruction performance by combining any one of the three neuron segmentation DNNs.
Consequently, the segmentation network and traditional tracing method can complement and promote each other, leading to more complete neuron reconstruction.


\subsubsection{Enhancement Parameter} 

In order to explore the influence of parameter $\alpha$ in Eq.~\eqref{equ: enhance} for image enhancement, we adopt different values for $\alpha$.
The results are shown in Fig.~\ref{fig:ablation_study_plnpr}~(c).
$\alpha=0$ means that the raw blocks are directly used as input for neuron tracing.
$\alpha=1$ means that only the probability maps are used as input for neuron tracing. 
It indicates that the performance is improved by combing the probability map with the raw image signal, mainly because that the probability map reflects the long-range trajectory structures while the raw image signal carries more details of subtle neurites.
In this paper, we empirically select $\alpha=0.1$ to reduce the influence of false positive predictions in probability maps due to the limited performance of the DNN model trained by pseudo labels and increase the robustness of the whole framework.

\delete{
\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\columnwidth]{./Illustrations/weight_paprameter7.pdf}
	\caption{Neuron reconstruction performance with different $\alpha$ in Eq.~\eqref{equ: enhance} for image enhancement on the VISoR-40 test dataset. From left to right, the value of $\alpha$ increases from $0$ to $1$ by a step of $0.1$.  }
	\label{fig:weight_paprameter}
\end{figure}
}


\subsubsection{Comparison with Tracing Methods}

\begin{figure*}[t]
	\centering
	\includegraphics[width=1\textwidth]{./Illustrations/comparison_visor.pdf}
	\caption{Comparison of neuronal population reconstruction results of three image blocks. %using neuron reconstruction methods FMST~\cite{Yang2019}, APP1~\cite{Peng2011}, APP2~\cite{Xiao2013}, SmartTracing~\cite{Chen2015}, MOST~\cite{Wu2014}, NGPST~\cite{Quan2015} and our PLNPR on three test images from the VISoR-40 dataset.
	%Each row shows the reconstruction results generated by different methods for a test image. The first column shows the raw images, while the last column shows the ground truth (GT). Each of the remaining columns shows the reconstruction result using the corresponding tracing method. 
	Our PLNPR method reconstructs more complete and accurate neurons compared to other methods. Separated neurons are shown in different colors.
	}
	\label{fig:compare_VISoR}
\end{figure*}


\begin{figure*}[t]
	\centering
	\subfloat[Precision]{
		\begin{minipage}[b]{0.23\linewidth}
			\centering
			\includegraphics[height=3cm]{./Illustrations/PLNPR_same_enhanced_images_Precision.pdf}
	\end{minipage}}
	\hspace{0.1cm}
	\subfloat[Recall]{
		\begin{minipage}[b]{0.23\linewidth}
			\centering
			\includegraphics[height=3cm]{./Illustrations/PLNPR_same_enhanced_images_Recall.pdf}
	\end{minipage}}
	\hspace{0.1cm}
	\subfloat[F-Score]{
		\begin{minipage}[b]{0.23\linewidth}
			\centering
			\includegraphics[height=3cm]{./Illustrations/PLNPR_same_enhanced_images_FScore.pdf}
	\end{minipage}}
	\hspace{0.1cm}
	\subfloat[Jaccard]{
	\begin{minipage}[b]{0.23\linewidth}
		\centering
		\includegraphics[height=3cm]{./Illustrations/PLNPR_same_enhanced_images_Jaccard.pdf}
\end{minipage}}
	\caption{ Performance comparison with seven neuron tracing methods on the raw VISoR-40 test images and on the images enhanced by our PLNPR.
		%, including APP2~\cite{Xiao2013}, SmartTracing (ST)~\cite{Chen2015}, TReMAP~\cite{Zhou2016}, MOST~\cite{Wu2014}, APP1~\cite{Peng2011}, FMST~\cite{Yang2019} and NGPST~\cite{Quan2015}.
	}
	\label{fig:PLNPR_same_enahcned_images}
\end{figure*}

\begin{table}[t]
	\centering
	\caption{Performance comparison with different methods for neuronal population reconstruction on the VISoR-40 test dataset.% given raw images and the same enhanced images as input.
	}
	\label{table:compare_VISoR}
	\begin{tabular}{lcccc}
		\toprule
		Method & Precision & Recall & F-Score & Jaccard\\ 
		\midrule
		APP2~\cite{Xiao2013} & \textbf{0.980} & 0.115 & 0.191 & 0.119\\
		SmartTracing~\cite{Chen2015} & 0.877 & 0.291 & 0.400 & 0.242\\
		TReMAP~\cite{Zhou2016} & 0.917 & 0.199 & 0.326 & 0.2039\\
		MOST~\cite{Wu2014} & 0.969 & 0.284& 0.434& 0.316\\
		APP1~\cite{Peng2011} & 0.935 & 0.201 & 0.328 & 0.205\\
		FMST~\cite{Yang2019} & 0.884 & 0.208 & 0.335 &  0.211\\
		NGPST~\cite{Quan2015} & 0.978 & 0.603 & 0.741 & 0.623\\
		\midrule
		Ours & 0.971 & \textbf{0.829} & \textbf{0.893} & \textbf{0.833}\\
		\bottomrule
		\hline
	\end{tabular}
\end{table}


%<18-AAAI-Adaptive Graph Convolutional Neural Networks>
To prove the effectiveness of our PLNPR on neuronal population reconstruction, we compare it with seven widely used neuron tracing methods, including APP1~\cite{Peng2011}, APP2~\cite{Xiao2013}, MOST~\cite{Wu2014}, SmartTracing (ST)~\cite{Chen2015}, NGPST~\cite{Quan2015}, TReMAP~\cite{Zhou2016}, and FMST~\cite{Yang2019}.
The parameters of these tracing methods are manually adjusted for each image block to get the best performance for fair comparison.
%
Fig.~\ref{fig:compare_VISoR} shows the neuronal populations reconstructed from three test image blocks.
We utilize NGPST as the base tracer with 3D DSN as the segmentation network as ``Ours''. 
The segmentation network is trained progressively on the VISoR-40 dataset in the training stage. 
We use the trained model directly at the test stage for evaluation. 
Compared with other methods, our PLNPR is superior in both sparse and dense neurons.
%
Table~\ref{table:compare_VISoR} compares the quantitative results of different methods with regard to the four metrics including precision, recall, F-Score, and Jaccard.
%
It shows that our PLNPR makes a significant improvement on the overall performance compared with other methods.
Though APP2~\cite{Xiao2013} achieves the highest precision, the reconstructed neurons are significantly sparser than others.
%
Conventional tracing methods~\cite{Peng2011, Xiao2013, Wu2014, Zhou2016} and learning-based methods~\cite{Chen2015, Yang2019} tend to extract the main trunk of neurons, while missing a large portion of subtle neurites. 
Therefore, these methods have very high precision but significantly lower recall.
Although NGPST~\cite{Quan2015} achieves better performance of neuronal population reconstruction compared with other single-neuron tracing methods, it still remains difficult to extract subtle neurites for NGPST by using hand-crafted features.
%
In comparison, our PLNPR benefits from the progressively trained segmentation network and reconstructs more complete neurons from these challenging blocks, even there exhibit noises, low contrast, and blending of fluorescence in the blocks.
%


%Furthermore,  the quantitative results of each tracing method when given raw images and the same enhanced images which are produced by our PLNPR method are compared in Table~\ref{table:compare_VISoR}. The results show that each method is promoted to achieve significantly higher overall performance and reconstruct more complete neuronal populations when using the same enhanced images as input.
Furthermore, in order to evaluate the effectiveness of our progressive learning framework to enhance images, we compare the reconstruction results of seven neuron tracing methods on the raw test images and on the same enhanced images generated by our PLNPR method in Fig.~\ref{fig:PLNPR_same_enahcned_images}.
For any of the seven tracing methods, the overall reconstruction performance, including F-Score and Jaccard, using our enhanced images are much better than the results performed on the raw images under the same parameter settings.
%Without losing to much precision, the recall and F-Score

\begin{figure*}[th]
	\centering
	\includegraphics[width=0.9\textwidth]{./Illustrations/BigNeuron_comparison_v2.pdf}
	\caption{Comparison of single neuron reconstruction results on two test images from the BigNeuron dataset.
		% using MOST~\cite{Wu2014}, FMST~\cite{Yang2019}, APP2~\cite{Xiao2013}, TReMAP~\cite{Zhou2016}, NGPST~\cite{Quan2015}, SmartTracing~\cite{Chen2015}, Li2017~\cite{Li2017} and our PLNPR on two testing images from the BigNeuron dataset.
		The reconstructed neurites are shown in blue and the corresponding ground truth (GT) are shown in red.
		Our method reconstructs more complete and accurate neurons compared to other methods.
	}
	\label{fig:compare_BigNeuron}
\end{figure*}

\begin{table*}[h]
	\centering
	\makeatletter\def\@captype{table}\makeatother
	\caption{Performance comparison for single neuron reconstruction on the BigNeuron test dataset.}
	\label{table:compare_BigNeuron}
	\begin{tabular}{lcccccccc}
		\toprule
		Method & Precision & Recall & F-Score & Jaccard & ESA & DSA & PDS\\
		\midrule
		MOST~\cite{Wu2014} & 0.629 & 0.508 & 0.541 & 0.593 & 31.730 & 38.211 & 0.633\\
		TReMAP~\cite{Zhou2016} & 0.771 & 0.508 & 0.578 & 0.525 & 11.269 & 17.941 & 0.539\\
		FMST~\cite{Yang2019} & 0.575 & 0.658 & 0.591 & 0.532 & 17.878 & 23.459 & 0.558\\
		neuTube~\cite{Feng2015} & 0.742&0.738&0.710&0.648&12.741&21.379&0.434&\\
		SmartTracing~\cite{Chen2015} & 0.701 & 0.722 & 0.613 & 0.465 & 10.430 & 13.430 & 0.547\\
		APP2~\cite{Xiao2013} & 0.875 & 	0.582 & 0.681 & 0.667 & 6.063 & 9.079 & 0.496\\
		NGPST~\cite{Quan2015} & 0.710 & 0.757 & 0.728 & 0.592 & 8.830 & 17.489 & 0.463\\
		MEIT~\cite{Wang2018} & 0.689  & 0.729 & 0.702 & 0.396 & 11.635 &15.772 & 0.544 \\
		UltraTracer~\cite{Peng2017} & 0.796 & 0.685 & 0.705 & 0.682 & 10.156 & 17.355 & 0.426 \\
		Li2017~\cite{Li2017} & - & - & - & - & 4.917 & 7.972 &0.461 \\
		\midrule
		PLNPR-APP2 & \textbf{0.877} & 0.616 & 0.713 & \textbf{0.706} & 5.020 & \textbf{7.753} & 0.492\\
		PLNPR-NGPST &0.783&\textbf{0.789}&\textbf{0.778}&0.691&\textbf{4.714}&9.458 & \textbf{0.428}\\
		% PLNPR-NGPST (VISoR-40+BigNeuron) & 0.769 & 0.777 & 0.768 & 0.683 & 4.694 & 8.082 & 0.445\\
		\bottomrule
	\end{tabular}
\end{table*}

\subsection{Evaluation of PLNPR on BigNeuron Dataset}
\label{sec:exp_PLNPR_BigNeuron}

\subsubsection{BigNeuron Dataset}

To validate our PLNPR method on single neuron reconstruction, we employ the BigNeuron~\cite{peng2015} dataset. 
This dataset consists of about $20,000$ 3D OM images acquired from a variety of species and optical imaging systems by different institutes.
%Some images have the corresponding manual annotations for evaluation.  
Unlike our VISoR-40 dataset which is built to evaluate neuronal population reconstruction, each image block in the BigNeuron dataset only contains a single neuron or fragmented neurites.
Following \cite{Li2017}, we select the same 68 images that are from a variety of species to evaluate the performance of dense neurite reconstruction.
Manual reconstruction by experts is associated with each image. 
51 images are used for network training in \cite{Li2017} and the remaining 17 images are used for evaluation.
In contrast, we do not use the manual annotations in our PLNPR to train the segmentation deep neural networks. 


\subsubsection{Experimental Settings}
 
 
To evaluate our PLNPR on single neuron reconstruction, we progressively train the DSN model on the BigNeuron dataset using pseudo labels generated by a conventional tracing method, such as NGPST~\cite{Quan2015} and APP2~\cite{Xiao2013}, instead of the provided manual annotations.
%
The learning rate was initialized as $\num{1e-4}$ and decayed using the ``poly" learning rate policy with power of $0.9$. The maximum iteration number is set to $ 24000 $. 
We cropped image patches of size $160\times 160\times 8$ as input to the segmentation DNN since the axial dimensions are usually much lower in the images of the BigNeuron dataset than our VISoR-40 dataset.
Data augmentation by transposing the three dimensions of each training image is also performed. 


\subsubsection{Comparison on BigNeuron Dataset}

\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{./Illustrations/comparison_ultranpr.pdf}
	\caption{Reconstruction results of dense neuronal populations from four adjacent large-scale blocks using UltraTracer~\cite{Peng2017}, MEIT~\cite{Wang2018}, NGPST~\cite{Quan2015} and our UltraNPR. The second row shows close-up views for a local region with dence neurites. Our method reconstructs more complete and distinguishable neurons. 
	}
	\label{fig:reconstruct_blocks}
\end{figure*}

\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{./Illustrations/brain_slice.pdf}
	\caption{The reconstruction result of neuronal populations in a large-scale 3D mouse brain slice using our UltraNPR method.}
	\label{fig:reconstruct_brain}
\end{figure}

On the BigNeuron dataset, we compare with ten widely-used tracing methods to validate the effectiveness of our proposed method.
They are MOST~\cite{Wu2014}, TReMAP~\cite{Zhou2016}, FMST~\cite{Yang2019}, neuTube~\cite{Feng2015}, SmartTracing~\cite{Chen2015}, APP2~\cite{Xiao2013}, NGPST~\cite{Quan2015}, Li2017~\cite{Li2017}, MEIT~\cite{Wang2018}, and UltraTracer~\cite{Peng2017} respectively.
%
While APP2~\cite{Xiao2013} performs well on the BigNeuron dataset, we also test our PLNPR with APP2 as the base tracer. 
``PLNPR-NGPST" means that we progressively train a DSN using the pseudo labels generated by NGPST~\cite{Quan2015}.
``PLNPR-APP2" means that the DSN model is progressively trained using the pseudo labels generated by APP2~\cite{Xiao2013}, which is same as the base tracer used in Li2017~\cite{Li2017}.
%In addition, we test our PLNPR by progressively learning with APP2~\cite{Xiao2013} (``PLNPR-APP2") which is same as the base tracer used in Li2017~\cite{Li2017}.



The four metrics, including precision, recall, F-Score, and Jaccard, are used for comparisons for most methods.
However, the implementation of the DNN-based method~\cite{Li2017} and its reconstruction results are not available.
In order to compare with \cite{Li2017}, we only compare the three evaluation metrics reported in \cite{Li2017} on the same test data.
%
The three metrics include the entire structure average (ESA), different structure average (DSA), and percentage of different structures (PDS), which are defined in~\cite{Peng2010a}.
While many conventional tracing methods require careful parameter tuning, we tuned parameters for each tracing method more than 10 times for each image block to find their optimal reconstructions for comparison.
%
The quantitative comparison is shown in Table~\ref{table:compare_BigNeuron}.
The weighted averages of the ESA, DSA and PDS are calculated by weighting each test block with the neuron length identified in the corresponding manual annotation.
For these three scores, lower values presents higher coincidence between the tracing results and the manual reconstruction.
%
From Table~\ref{table:compare_BigNeuron}, we can see that our method outperforms other methods on the BigNeuron test dataset.
%Though APP2~\cite{Xiao2013} achieves the highest precision, a large portion of subtle neurites are missing, as shown in Fig.~\ref{fig:compare_BigNeuron}.
%
Comparing with the deep learning-based method~\cite{Li2017}, both our PLNPR-APP2 and PLNPR-NGPST achieve comparable performance.
However, our method does not require any manual annotations to train the deep segmentation network.
With ever-increasing number of unlabeled neuron datasets are collected, our method could utilize them to further improve the performance of neuron reconstruction.
%
Fig.~\ref{fig:compare_BigNeuron} shows the reconstructed neurons in two test images using different tracing methods. 


\subsection{Evaluation of UltraNPR on a Mouse Brain Slice}
\label{sec:exp_UltraNPR}

%\subsubsection{Experimental Settings}
To reconstruct the dense neuronal population from an ultra-scale mouse brain image, we divide the entire image into blocks in size of $1120\times 2048\times 869$ considering the memory and computational cost of our PLNPR.
%
The overlap between adjacent blocks is set to be $300$ voxels along each dimension. 
The $\delta_{ovlp}$ is set to be 10 voxels, the $\delta_{bound}$ is set to be 70 voxels and the $\delta_{pt}$ is set to be 10 voxels for neurite fusion in Sec.~\ref{sec:fusion}.
%
It took our UltraNPR 34 hours for image segmentation with 3D DSN, one hour for neuron reconstruction in blocks, and 10 hours for neurite fusion to reconstruct the dense neuronal population from the entire image on a cluster computer with $64$ GB working memory and 20 NVIDIA 1080Ti GPUs.
%
As shown in Fig.~\ref{fig:reconstruct_brain}, a neuronal population consisting of $5348$ neurons is successfully reconstructed by our UltraNPR from the ultra-scale noisy OM image. 


Since it is infeasible to manually annotate the dense neuronal population in an ultra-scale image, quantitative evaluation of the reconstruction performance is not supported.
%
However, we select four adjacent large-scale image blocks to qualitatively compare our UltraNPR with two state-of-the-art methods, UltraTracer~\cite{Peng2017} and MEIT~\cite{Wang2018}, for large-scale neuron reconstruction.
We also compare our UltraNPR with NGPST~\cite{Quan2015}, which is the state-of-the-art method for neuronal population reconstruction from local image blocks.
Since the sheer volume of these four image blocks is far beyond the processing capability of NGPST, we extend NGPST by using the raw image blocks as input to trace neurons and utilizing our block propagation and neurite fusion strategies to achieve the large-scale neuonal population reconstruction.
%


\begin{figure}[t]
	\centering
	\includegraphics[width=\columnwidth]{./Illustrations/single_neurons4.pdf}
	\caption{Single neurons selected from the reconstructed neuronal populations in a mouse brain slice using our UltraNPR method.}
	\label{fig:single_neurons}
\end{figure}

Fig.~\ref{fig:reconstruct_blocks} compares the results of large-scale neuronal population reconstruction using different methods on the four image blocks. 
%
MEIT~\cite{Wang2018} is designed for tracing single neuron. Therefore, it can not separate individual neurons. 
Moreover, it fails to reconstruct the subtle neurites due to the noises and low contrast in this challenging image.
UltraTracer~\cite{Peng2017} achieves better performance of neuronal population reconstruction from the large-scale image. 
However, for the local regions with low signal-noise-ratio, it fails to separate individual neurons and trace complete neurites in a dense neuronal population.
Although NGPST~\cite{Quan2015} can reconstruct separated neurons successfully, it still remains difficult to reconstruct complete neuronal populations from the challenging image for NGPST using hand-crafted features.
In comparison, thanks to the signal enhancement by our deep network and block propagation designed for dense neurites, our UltraNPR is more robust to reconstruct a more complete neuronal population from the low-quality image while individual neurons are continuously and smoothly traced.



Several neurons selected from the reconstructed neuronal population are visualized in Fig.~\ref{fig:single_neurons}. 
We believe that these ultra-scale reconstructions provide detailed neuronal structures and will effectively support further neuronal morphology analysis in the whole brain. 
In summary, without any manual annotations and human interaction, our UltraNPR is capable of reconstructing dense neuronal populations from ultra-scale noisy OM images. 
